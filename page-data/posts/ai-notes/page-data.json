{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/posts/ai-notes/","result":{"data":{"markdownRemark":{"id":"c44a344f-8452-56bb-aeb7-386c407155fd","html":"<h2 id=\"supervised-learning\" style=\"position:relative;\"><a href=\"#supervised-learning\" aria-label=\"supervised learning permalink\" class=\"custom-name before\">#</a>Supervised Learning</h2>\n<p>The supervised learning used to label training data.\nExamples: </p>\n<ul>\n<li>Classification(KNN algorithm, Support Vector Machine)</li>\n<li>Regression (Linear Regression, Lasso, Ridge)</li>\n<li>Neural Networks (Convolutional Neural Network)</li>\n</ul>\n<h3 id=\"data-type\" style=\"position:relative;\"><a href=\"#data-type\" aria-label=\"data type permalink\" class=\"custom-name before\">#</a>Data Type</h3>\n<p>The raw data consists of these few types:</p>\n<ol>\n<li><strong>Discrete</strong>: The discrete data only take certain values. Like throwing a dice, you obtained only 1,2,…,6. These\nintegers are discrete.</li>\n<li><strong>Continuous</strong>: These data are continuous and can have any real values within an interval.</li>\n<li><strong>Ordinal</strong>: You cannot compare such ordinal data. For instance, gender, street name, etc.</li>\n<li><strong>Nominal</strong>: Nominal data allowed you to rank their numerical values. Example: exam ranking.</li>\n<li><strong>Interval</strong>: In interval data, the zero value has its own meaning. For instance, 0 degree celsius\ndoesn’t implies no temperature exists. It just used to differentiate whether temperature values\nare positive or negative.</li>\n<li>Ratio: In ratio data, the zero values doesn’t contain any meaning. For instance, when someone\ngetting 0% in a test, and his marks really contain nothing.</li>\n</ol>\n<h3 id=\"overfitting-underfitting\" style=\"position:relative;\"><a href=\"#overfitting-underfitting\" aria-label=\"overfitting underfitting permalink\" class=\"custom-name before\">#</a>Overfitting, Underfitting</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5491d50bee7466b41b0dc3aedd51b745/6bbf7/fitting.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 33.108108108108105%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAABe0lEQVQoz02R6U7DMBCE8/5PwxsgIUDqAZS06UGaq0nqXK1zNXcZdo2E+GGt5dF+ntnV+q5DlpdwvBPCIEBd1yiKAkIIjOOIjvS+71Vt2xbjMMDyfJwziVvT4Ha7qZ6qqpDnOTRuzi4XfOo65vM5XNdFVZbQjR1CEeN+n/6gDQHwfce78YWH5zWyskHzD8gsbWf7SK+Sfqff6goTuSoI6PsBRJwiI22afp0O5G4ae7ztXSx2DrwwwtC1qAjI4JKBRd1guTFhBglk3cI4mDgx7Hwmd3dY7kk5ZWdb06HR+JhtHcRXSmEF0A8Wue/gUs/Tcg1toChMXqzWeP0wsNzZyIsSUSSUI9Y3exOzlYGZvsc09Hg1XIhUoif9Y3vE42yFl7c1zJOAJqWElDlyqmmaqHlcKWZAC+K5lBSfaxQnakYccUlxA3JdlYWa91lEiJMElyyDxkvgY9u22qzv+wS8EjxFGIbqsB5FkdL4nXW+s3Y8WvA8D67jwLIs/ADNGQpJc2hbHwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Fitting\"\n        title=\"Fitting\"\n        src=\"/static/5491d50bee7466b41b0dc3aedd51b745/fcda8/fitting.png\"\n        srcset=\"/static/5491d50bee7466b41b0dc3aedd51b745/12f09/fitting.png 148w,\n/static/5491d50bee7466b41b0dc3aedd51b745/e4a3f/fitting.png 295w,\n/static/5491d50bee7466b41b0dc3aedd51b745/fcda8/fitting.png 590w,\n/static/5491d50bee7466b41b0dc3aedd51b745/6bbf7/fitting.png 716w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>The <strong>underfitting</strong> (The left one) occured when your data is poorly trained (You can observed that the fitting curve is linear),\nand this implies that your model do not “learn” enough. The bias for underfitting is higher, but it has a lower variance.</p>\n<p>When you run an <strong>overfitting model</strong> (the right figure), your error (distance from each point to the line) will become\nsmaller with more iterations. This is because your fitting curve almost connect up every single\npoint of the data (Our task is fitting a model, not connect them together). The bias for underfitting is lower, but it has a higher variance.</p>\n<p>You can check the cross validate scores of your model. If your tested scores is around 75-80, then it is a right fitting model.\nOtherwise, if the cross validate scores is <strong>extremely high (99-100 percent)</strong>, then this considered as overfitting.</p>\n<h3 id=\"data-transformation\" style=\"position:relative;\"><a href=\"#data-transformation\" aria-label=\"data transformation permalink\" class=\"custom-name before\">#</a>Data Transformation</h3>\n<p><strong>Standard Scaler</strong></p>\n<blockquote>\n<p>Please take note that you cannot directly applied\n<code class=\"language-text\">sklearn.preprocessing</code> on 1D-array (like assignment 2 Q2). You need to define your\nown methods for scaling.</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">standard_scaler</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># data is array type</span>\n  mu <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n  std <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> ddof<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">for</span> val <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>val <span class=\"token operator\">-</span> mu<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> std<span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>MinMax Scaler</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">minmax_scaler</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># data is array type</span>\n  max_value <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n  min_value <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">for</span> val <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>val <span class=\"token operator\">-</span> min_value<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>max_value <span class=\"token operator\">-</span> min_value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>Max Absolute Scaler</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">max_abs_scaler</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># data is array type</span>\n  max_value <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>data <span class=\"token operator\">/</span> max_value<span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>Robust Scaler</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">robust_scaler</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># data is array type</span>\n  q1 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>percentile<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> <span class=\"token number\">25</span><span class=\"token punctuation\">)</span>\n  q2 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>percentile<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n  q3 <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>percentile<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> <span class=\"token number\">75</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">for</span> val <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>val <span class=\"token operator\">-</span> q2<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>q3 <span class=\"token operator\">-</span> q1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>One-hot encoding</strong>: Convert your data into binary values. Data type: <code class=\"language-text\">int</code>, <code class=\"language-text\">bool</code></p>\n<p><strong>Ordinal encoding</strong>: Convert your data into ordinal integers.\nData type: <code class=\"language-text\">int</code>, <code class=\"language-text\">char</code> (Char is 1 byte = 8 bits, you can use <code class=\"language-text\">Char</code> if number of classes is less than 8) </p>\n<p><strong>Logistic Regression</strong></p>\n<blockquote>\n<p>Logistic Regression <strong>is not really about regression</strong>. Instead, it is a classification,\nand also a binary classifier.</p>\n</blockquote>\n<h3 id=\"confusion-matrix\" style=\"position:relative;\"><a href=\"#confusion-matrix\" aria-label=\"confusion matrix permalink\" class=\"custom-name before\">#</a>Confusion Matrix</h3>\n<p>Confusion matrix used to visualize the number of true positive (TP),\ntrue negative (TN), false positive (FP) and false negative (FN). </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/00f2916d791dbebfcf0b127f3a6a394f/136a2/confusion.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAACMUlEQVQozz2SWU9TURSF73/UBI0RHiClCYkPTbTEBkETjU8YE4fQB8UAmmBCAq3ghFJMjZRgC53pPN3OlA63xdLmc98r8rByTs45e+111l5KsVikUqlwcnJCV+ugtVtEQkFCAT/1WpXh4Jy63KWyWXIFlXgqZewbrRZat0tL1tPTU2q1GuVyGaVardJsNg1k8lKQKXBwFGTP6yeezpPKF8kcH5MNhchFIqSDQQM5OdM6HbpC2pFVr6/X6yjJZJKgPCgVVV65otjWjrj33oPtrZu5NR/3HSHc0zP8njSxazLxfWKCvUkzfouFmDRpiLpyqYSqFsmKciWRSOD1elHzORa+hbFtRLCt7nN7yc2DD9JgPYDLYiVsNuEeH2d7bIwjsxnf1BQ+j4ey2JUTonQ6TTweQykJe1FVqYlPP57bcVru4rDOGticnmPrzgwvXq7x9PVnntg3mF9YZ97u5NmbLxRLFfr9vuFlu902vFR8os61s0NMzI4+eoj/+gi710b4evUKh6M3CYze4PG7X1g/Zbi19BOTfRvrxjGzH5Okcypnva7hX6PRQJ+Hooo6fTq6wsjmJtHlFUIrKxwuLhJfXSWwvMyWy4vzII3TE8MhcO4ncOxFqVRrkgzNINRToqdFMWIjzPqEmnKpDQbURX5GznvDIb3BkPM/Z5yfdS/R72kGtIvp6ur02Oj2Kfl8nsssCmlJFEfCYVIyfbVQMIrabUHnArJvScOmkb9/yv5nUP/tX4RNbFhnwCA8AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Confusion\"\n        title=\"Confusion\"\n        src=\"/static/00f2916d791dbebfcf0b127f3a6a394f/fcda8/confusion.png\"\n        srcset=\"/static/00f2916d791dbebfcf0b127f3a6a394f/12f09/confusion.png 148w,\n/static/00f2916d791dbebfcf0b127f3a6a394f/e4a3f/confusion.png 295w,\n/static/00f2916d791dbebfcf0b127f3a6a394f/fcda8/confusion.png 590w,\n/static/00f2916d791dbebfcf0b127f3a6a394f/136a2/confusion.png 884w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<blockquote>\n<p>If we predicted someone being infected by virus, and he really is, then\nthis is consider as TP. If we predicted he is healthy and he isn’t infected,\nthen this is TN.</p>\n</blockquote>\n<p>On the other hand, if we wrongly predicted, for instance,</p>\n<blockquote>\n<p>If the test subject is healthy but we wrongly predicted him an infected, then\nthis situation is called FP. </p>\n</blockquote>\n<p>The type I and type II errors are not only occured test of hypotheses in statistics.\nThey can be occured when performing A/B testing (or split-run testing). A/B testing\nusually applied in marketing or digital products (Mobile apps UI design, apps features, etc.).\nIt tests randomly on two customers A and B, then we compare their experience.</p>\n<h3 id=\"roc-curve-auc-curve\" style=\"position:relative;\"><a href=\"#roc-curve-auc-curve\" aria-label=\"roc curve auc curve permalink\" class=\"custom-name before\">#</a>ROC Curve, AUC Curve</h3>\n<p>The ROC curve defined how good is your model. If your tested score is above the diagonal line,\nthen yours should be a robust model.</p>\n<p>The AUC denotes the area under ROC curve. Its area described how accurate is your True Positive.</p>\n<h2 id=\"unsupervised-learning\" style=\"position:relative;\"><a href=\"#unsupervised-learning\" aria-label=\"unsupervised learning permalink\" class=\"custom-name before\">#</a>Unsupervised Learning</h2>\n<p>The different between unsupervised learning and supervised learning is: supervised learning consists\nof labeled training data and some training examples, which the pattern has been determined. For\nunsupervised learning, we are given the clusters (or group), but the tested data has unidentified\npattern. </p>\n<p>Examples: </p>\n<ul>\n<li>Clustering (K Means, mixture models)</li>\n</ul>\n<h3 id=\"dimensionality-reduction\" style=\"position:relative;\"><a href=\"#dimensionality-reduction\" aria-label=\"dimensionality reduction permalink\" class=\"custom-name before\">#</a>Dimensionality Reduction</h3>\n<p>To prevent the <strong>curse of dimensionality</strong>, you should eliminate the unwanted features. The cost\nfor training dataset will increase exponentially akin to the number of features. We can manually\nselect the features that are highly correlated or applied <strong>principle component analysis (PCA)</strong>\non dataset.</p>\n<h2 id=\"genetic-algorithm\" style=\"position:relative;\"><a href=\"#genetic-algorithm\" aria-label=\"genetic algorithm permalink\" class=\"custom-name before\">#</a>Genetic Algorithm</h2>\n<p>Generally, the genetic algorithm involved 3 operations: <strong>crossover</strong>, <strong>mutation</strong>, and <strong>selection</strong>.</p>\n<ol>\n<li>crossover: Swapping two chromosomes (bit-array) randomly.</li>\n<li>mutation: Flipping the value in gene. For instance: 101 -> 010</li>\n<li>selection: we choose the best solution and inherits to next step.</li>\n</ol>\n<p>Once finished the three operations above, the process will repeat again until the iterations over.</p>\n<p>In fact, GA algorithm has been depreciated since it cannot effectively solve problem.\nFor instance, you’ll found that no hill to climb in <strong>gradient descent</strong>. Even the random\ntree search algorithm is faster than GA!</p>\n<p><strong>Historical fact:</strong> The 2006 NASA ST5 spacecraft has adopted GA algorithm to create\nthe best radiation pattern for <a href=\"https://en.wikipedia.org/wiki/Evolved_antenna\">evolved antenna</a>.</p>\n<h3 id=\"selection-pressure\" style=\"position:relative;\"><a href=\"#selection-pressure\" aria-label=\"selection pressure permalink\" class=\"custom-name before\">#</a>Selection Pressure</h3>\n<p>The fitness function is defined as below:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 183px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4f9213f422de40c7703c3cfb54588b82/e6f05/fitness_func.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABZ0lEQVQoz3VSa2+CQBD0//8T/dg2qW21D6uN1lgQRBRoAYmgqBVFQHlNDyKiVie53HK3zM3ObgEEcRwfVvad4Tg+RQzHdZFdZ3mFc8LzlWDruVhaFqhOG9XnV+jGBPXaC94bzT1ZlBNeV5C/as0naH22cXd7A3U8hchReKs34W39k7xkTxX+zmcol8ukBC8txfU8RFH+UBSF0Mdj7Hwf5tQAPxQPJEEQ7OM4LT8l5BgKj5UXmKaJ5WKGp0oV7nYHRZZB0zRYloEgSlBVFZIkQZaVNBZFAepohCHfJ5ascg839hpBGMHQ9fQwDMN0F3gOXzSDTqsBhZSaYGLokL9FFIslMNwAwqCPUrGIxcq+7OFxMzSFKOyymM/MtBH2ygLTpYl/H+j1WNi2g8rDPX5G2uH/f11OjMj8E4c8arU6ujQFVdPAMCzW6zU2jkuM9SEIAhxvdyKkcEnZtfnzyNzljSKjchzv8/8AXpmt8LtEGZ8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Fitness Function\"\n        title=\"Fitness Function\"\n        src=\"/static/4f9213f422de40c7703c3cfb54588b82/e6f05/fitness_func.png\"\n        srcset=\"/static/4f9213f422de40c7703c3cfb54588b82/12f09/fitness_func.png 148w,\n/static/4f9213f422de40c7703c3cfb54588b82/e6f05/fitness_func.png 183w\"\n        sizes=\"(max-width: 183px) 100vw, 183px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Given that:</p>\n<blockquote>\n<p>P1’=0.05, P2’=0.11, P3’=0.12, P4’=0.24, P5’=0.48, and beta=0.5.</p>\n</blockquote>\n<p>Use the fitness function above, find P1, P2, P3, P4, and P5.</p>\n<blockquote>\n<p>ANSWER: P1=0.1073, P2=0.1591, P3=0.1662, P4=0.2350, P5=0.3324 (total sum=1).</p>\n</blockquote>\n<h2 id=\"neural-network\" style=\"position:relative;\"><a href=\"#neural-network\" aria-label=\"neural network permalink\" class=\"custom-name before\">#</a>Neural Network</h2>\n<p>The neural network has 3 layers: <strong>Input layer</strong>, <strong>Hidden layer</strong>, <strong>Output layer</strong>.</p>\n<p>You might heard of “black box”. The hidden layer is also similar to it.\nThe Convolutional Neural Network (CNN) uses multiple hidden layers (or perceptrons).\nInside these hidden layers, it perform <a href=\"https://en.wikipedia.org/wiki/Cross-correlation\">sliding dot products</a> to\ntensors input.</p>\n<h3 id=\"training-process\" style=\"position:relative;\"><a href=\"#training-process\" aria-label=\"training process permalink\" class=\"custom-name before\">#</a>Training Process</h3>\n<p>The “training” mentioned that the weights are adjusted to\nmore accurate output, and the process that adjust these\nweights is known as <strong>backpropagation</strong>. </p>\n<h2 id=\"conclusion-shameless-plug\" style=\"position:relative;\"><a href=\"#conclusion-shameless-plug\" aria-label=\"conclusion shameless plug permalink\" class=\"custom-name before\">#</a>Conclusion: Shameless Plug</h2>\n<p>In my own opinion: FA calculations might be: (They are easier for calculation)</p>\n<ul>\n<li>Confusion matrix (Accuracy score, specificity, etc.)</li>\n<li>Selection Pressure</li>\n<li>Neural Network</li>\n</ul>\n<p>(I didn’t prepare much, since the FA is similar to assignment 2)</p>","excerpt":"Supervised Learning The supervised learning used to label training data. \nExamples:  Classification(KNN algorithm, Support Vector Machine) Regression (Linear…","tableOfContents":"<ul>\n<li>\n<p><a href=\"/posts/ai-notes/#supervised-learning\">Supervised Learning</a></p>\n<ul>\n<li><a href=\"/posts/ai-notes/#data-type\">Data Type</a></li>\n<li><a href=\"/posts/ai-notes/#overfitting-underfitting\">Overfitting, Underfitting</a></li>\n<li><a href=\"/posts/ai-notes/#data-transformation\">Data Transformation</a></li>\n<li><a href=\"/posts/ai-notes/#confusion-matrix\">Confusion Matrix</a></li>\n<li><a href=\"/posts/ai-notes/#roc-curve-auc-curve\">ROC Curve, AUC Curve</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/posts/ai-notes/#unsupervised-learning\">Unsupervised Learning</a></p>\n<ul>\n<li><a href=\"/posts/ai-notes/#dimensionality-reduction\">Dimensionality Reduction</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/posts/ai-notes/#genetic-algorithm\">Genetic Algorithm</a></p>\n<ul>\n<li><a href=\"/posts/ai-notes/#selection-pressure\">Selection Pressure</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/posts/ai-notes/#neural-network\">Neural Network</a></p>\n<ul>\n<li><a href=\"/posts/ai-notes/#training-process\">Training Process</a></li>\n</ul>\n</li>\n<li><a href=\"/posts/ai-notes/#conclusion-shameless-plug\">Conclusion: Shameless Plug</a></li>\n</ul>","fields":{"slug":"/posts/ai-notes/"},"frontmatter":{"title":"AI Study Notes (Temporary)","date":"September 30, 2020","description":"AI Study Notes(Temporary)"}}},"pageContext":{"slug":"/posts/ai-notes/"}},"staticQueryHashes":["1194762247","1773691459","864671932"]}